{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task_handout.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/Colab/blob/main/Task_handout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH8yC7Z1-ya5",
        "outputId": "1aef3441-57b0-4394-92fc-af9580ab617d"
      },
      "source": [
        "! python -m spacy download en\n",
        "! pip install wordcloud\n",
        "! wget https://gitlab.com/andras.simonyi/10_days_AI_training_data/raw/master/sentiment.tsv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.19.5)\n",
            "--2021-02-05 19:24:46--  https://gitlab.com/andras.simonyi/10_days_AI_training_data/raw/master/sentiment.tsv\n",
            "Resolving gitlab.com (gitlab.com)... 172.65.251.78, 2606:4700:90:0:f22e:fbec:5bed:a9b9\n",
            "Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘sentiment.tsv’\n",
            "\n",
            "sentiment.tsv           [ <=>                ] 437.05K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-02-05 19:24:47 (3.09 MB/s) - ‘sentiment.tsv’ saved [447540]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKNqb75Iy-Yw"
      },
      "source": [
        "# Feladat: \"érzelemosztályozás\" (sentiment classification)\n",
        "\n",
        "A feladat egymondatos filmértékelések \"érzelmi tartalmának\" osztályozása. Csak két kategóriával dolgozunk: egy értékelés vagy negatív, vagy pozitív tartalmú.\n",
        "\n",
        "> \"Adatforrás: [UMICH SI650 - Sentiment Classification](https://www.kaggle.com/c/si650winter11/data)\n",
        "\n",
        "> Tréning adat: 7086 sor. \n",
        "  \n",
        "> Formátum: 1|0 (tab) mondat\n",
        "\n",
        "> Az adatokat eredetileg az opinmind.com gyűjtötte össze, ami azóta megszűnt.\n",
        "\n",
        "Az adatok a \"sentiment.tsv\" fájlban találhatók."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWjIpjZBy-Y2"
      },
      "source": [
        "# Adatbetöltés"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "S9liEvjzy-Y7",
        "outputId": "f618d330-c5bf-439f-f3ff-b0d88ae255d7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('sentiment.tsv', sep='\\t', \n",
        "                 quoting=3, # Quotes are _never_ field separators\n",
        "                 header=None)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Da Vinci Code book is just awesome.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>this was the first clive cussler i've ever rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>i liked the Da Vinci Code a lot.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>i liked the Da Vinci Code a lot.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                                  1\n",
              "0  1            The Da Vinci Code book is just awesome.\n",
              "1  1  this was the first clive cussler i've ever rea...\n",
              "2  1                   i liked the Da Vinci Code a lot.\n",
              "3  1                   i liked the Da Vinci Code a lot.\n",
              "4  1  I liked the Da Vinci Code but it ultimatly did..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "HRLzOOkny-ZO",
        "outputId": "94763ae8-220d-4f2e-c500-780d6a9aa84e"
      },
      "source": [
        "df = df[[1,0]] # oszlopok átrendezése\n",
        "\n",
        "df.rename(columns={1:\"text\", 0:\"sentiment\"}, inplace=True) # oszlopok átnevezése\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Da Vinci Code book is just awesome.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this was the first clive cussler i've ever rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i liked the Da Vinci Code a lot.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i liked the Da Vinci Code a lot.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0            The Da Vinci Code book is just awesome.          1\n",
              "1  this was the first clive cussler i've ever rea...          1\n",
              "2                   i liked the Da Vinci Code a lot.          1\n",
              "3                   i liked the Da Vinci Code a lot.          1\n",
              "4  I liked the Da Vinci Code but it ultimatly did...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-urvA8RDy-Zc"
      },
      "source": [
        "# Feladat: Tréning, validációs és tesztanyagra osztás"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS5wjfjEy-Ze"
      },
      "source": [
        "Mielőtt bármi másba fognánk (!), osszuk fel tréning, validációs és teszt részekre az adatokat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcMx4I5gy-Zh",
        "outputId": "cc6365c3-5028-4dbd-8e62-d16bd7757d5a"
      },
      "source": [
        "# Importáljuk be a Scikitből a szükséges függvényt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Figyeljük meg, hogy egyszerre csak kétfelé tud osztani, így akkor járunk jól,\n",
        "# ha kétszer ismételjük a hívást, \"láncban\"\n",
        "# Ne felejtsük el fixálni a random seed-et, mondjuk 13-ra, mert az olyan szerencsés szám!:-)\n",
        "df_train, df_test_valid = train_test_split(df,random_state=13)\n",
        "\n",
        "df_test, df_valid = train_test_split(df_test_valid, random_state=13)\n",
        "\n",
        "#assert len(df_train)==5668 and len(df_valid)==709 and len(df_test)==709\n",
        "print(len(df_train), len(df_valid), len(df_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5314 443 1329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCbUUTBty-Zq"
      },
      "source": [
        "# Adatelemzés"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "pMZv_My5y-Zt",
        "outputId": "1a03c095-53ab-43ec-fdc6-6749d74a3ae6"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5314.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.557960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.496676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "count  5314.000000\n",
              "mean      0.557960\n",
              "std       0.496676\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%       1.000000\n",
              "75%       1.000000\n",
              "max       1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhMtyNyGy-Z4"
      },
      "source": [
        "Megvizsgálhatjuk a mondatok hosszát is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_a-pzhcy-Z7",
        "outputId": "ac0225ba-d1c0-47f7-b223-d2c2ee636c4c"
      },
      "source": [
        "n_chars = df_train.text.apply(lambda x: len(x))\n",
        "\n",
        "n_chars.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    5314.000000\n",
              "mean       60.263831\n",
              "std        37.885590\n",
              "min        18.000000\n",
              "25%        32.000000\n",
              "50%        48.000000\n",
              "75%        77.000000\n",
              "max       203.000000\n",
              "Name: text, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UalJeEyOy-aJ"
      },
      "source": [
        "The first sentence with the maximal length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tujl0aK-y-aO",
        "outputId": "3f8ef97c-ad30-4951-91fb-1f5f89a4b748"
      },
      "source": [
        "long_sentence = df_train.loc[n_chars.idxmax(), \"text\"]\n",
        "long_sentence"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A mother in Georgia wants her local school board to take Harry Potter out of the schools and libraries because, in her opinion, reading Harry Potter leads to witchcraft, which according to her is evil...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr0k2LGsy-ag"
      },
      "source": [
        "# Extra feladat: készítsünk szófelhőt!\n",
        "\n",
        "Vizualizáljuk együttesen és kategóriánként a mondatokat!\n",
        "\n",
        "Eszköz: https://github.com/amueller/word_cloud\n",
        "\n",
        "\n",
        "Egy jó péda: https://github.com/amueller/word_cloud/blob/master/examples/simple.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wo1OyNdy-ak"
      },
      "source": [
        "# Segédfunkció a szófelhőhőz\n",
        "# Input: egy _EGYSÉGES_, space-szel elválasztott string!\n",
        "# Protip: https://www.tutorialspoint.com/python/string_join.htm\n",
        "def do_wordcloud(text):\n",
        "    from wordcloud import WordCloud\n",
        "    \n",
        "    # Szófelhő kép létrehozása\n",
        "    wordcloud = WordCloud().generate(text)\n",
        "\n",
        "    # Létrehozott kép megjelenítése:\n",
        "    # Nyilván tehettük volt szebb helyre is az importot... :-P\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # alacsonyabb max_font_size\n",
        "    wordcloud = WordCloud(max_font_size=40).generate(text)\n",
        "    plt.figure()\n",
        "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8vuQclYy-av"
      },
      "source": [
        "### OPCIONÁLIS FELADAT !!! ####\n",
        "# Hívjuk meg a szófelhő függvényt!\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2j3sI2Dy-a0"
      },
      "source": [
        "### TASK !!! ####\n",
        "# Tegyük meg ugyanezt, csak a negatív hangulatúnak besorolt mondatokkal!\n",
        "# Segítség: A csak negatív hanglatú sorokat tartalmazó DataFrame alakja: (2975, 2)\n",
        "# Forrás: https://pandas.pydata.org/pandas-docs/stable/indexing.html\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-GafZ4Py-a9"
      },
      "source": [
        "# Bag of words (BoW) szövegreprezentáció\n",
        "\n",
        "Minden mondatot egy olyan (ritka) fix hosszúságú vektorral fogunk jellemezni, amely a mondatban előfoduló lemmák (~ szótövek) számát tartalmazza a tréningadatban előforduló gyakori lemmákra. \n",
        "\n",
        "A szavakra bontásra és lemmatizálásra a nyílt forráskódú [spaCy](https://spacy.io/) Python NLP könyvtárt használjuk, amely egy egyedi lemmaazonosítókból álló listát képes előállítani a szövegekből."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msjbzya6y-a_"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en\", disable=[\"parser\", \"ner\"]) \n",
        "# Csak a szófelbontásra van szülsgünk, magasabb funkciókra nem"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-wKS3rZy-bE"
      },
      "source": [
        "A spaCy a szöveg nyelvészeti elemzését tartalmazó Doc objektumokat állít elő. Ezek az objektumok a szavak lemmaazonosítóit is tartalmazzák."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mNl6cRyy-bH",
        "outputId": "f5a65779-2e03-4e1c-ff6b-129f080c54a4"
      },
      "source": [
        "doc = nlp(long_sentence)\n",
        "type(doc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDVWmOamy-bP",
        "outputId": "6b574de0-9f55-4291-cf38-795a5693ae10"
      },
      "source": [
        "print([token.lemma_ for token in doc ]) # Lemmák"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'mother', 'in', 'Georgia', 'want', '-PRON-', 'local', 'school', 'board', 'to', 'take', 'Harry', 'Potter', 'out', 'of', 'the', 'school', 'and', 'library', 'because', ',', 'in', '-PRON-', 'opinion', ',', 'read', 'Harry', 'Potter', 'lead', 'to', 'witchcraft', ',', 'which', 'accord', 'to', '-PRON-', 'be', 'evil', '...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kklNRbxey-bX",
        "outputId": "6afa67f8-6b04-457c-f267-be691c528c5f"
      },
      "source": [
        "print([token.lemma for token in doc]) # Kapcsolódó egyedi id-k"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11901859001352538922, 7963322251145911254, 3002984154512732771, 309210702643012516, 7597692042947428029, 561228191312463089, 16319852998319793599, 13293160603192985325, 14899812206273857344, 3791531372978436496, 6789454535283781228, 5164779919001708464, 2416965663249996073, 1696981056005371314, 886050111519832510, 7425985699627899538, 13293160603192985325, 2283656566040971221, 1785747669126016609, 16950148841647037698, 2593208677638477497, 3002984154512732771, 561228191312463089, 14536103007527724270, 2593208677638477497, 11792590063656742891, 5164779919001708464, 2416965663249996073, 82546335403996757, 3791531372978436496, 17905374590688478165, 2593208677638477497, 7063653163634019529, 701735504652304602, 3791531372978436496, 561228191312463089, 10382539506755952630, 15036397985088571056, 10875615029400813363]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVDIxcI_y-br"
      },
      "source": [
        "Ezeket a lemma id listákat BoW vectorokká kell alakítanunk. Megpróbálhatnánk az egészet egyedül megírni, de szerencsére erre nincs szükség, mert a scikit-learn tartalmaz egy feature-extractort, ami pontosan ezt csinálja: ez a  [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer). Az egyszerűség kedvéért ezt használjuk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIPLl6eDy-bx",
        "outputId": "94eaad60-e782-4c77-efc3-d010246508e2"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(analyzer=lambda s: [token.lemma for token in nlp(s)], #spaCy az elemzéshez\n",
        "                     min_df= 0.001) # Ignoráljuk az alacsony dolkumentum gyakoriságú lemmákat\n",
        "cv\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer=<function <lambda> at 0x7f1bf93f1048>, binary=False,\n",
              "                decode_error='strict', dtype=<class 'numpy.int64'>,\n",
              "                encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
              "                max_features=None, min_df=0.001, ngram_range=(1, 1),\n",
              "                preprocessor=None, stop_words=None, strip_accents=None,\n",
              "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
              "                vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye0Hc8hOy-cP",
        "outputId": "c8e29825-1725-48ad-ac59-5cd10759de3d"
      },
      "source": [
        "\n",
        "sents = [\"I hate this movie.\", \"The movie is the worst I've seen.\"]\n",
        "bows = cv.fit_transform(sents).toarray() \n",
        "# A CountVectorizer egy ritka mátrixot produkál, így ndarray konverziót hajtujnk végre\n",
        "bows"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 1, 0, 0, 0, 1, 0, 1],\n",
              "       [1, 0, 2, 0, 1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BMQTcX5y-cg"
      },
      "source": [
        "A CountVectorizer segítségével az adataink text oszlopát ritka mátrixokká alakítjuk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo9nOv7jy-ci",
        "outputId": "25507a59-2097-434e-b988-aba777f42ba5"
      },
      "source": [
        "bows_train = cv.fit_transform(df_train.text)\n",
        "bow_length = bows_train.shape[1]\n",
        "print(\"BoW length:\", bow_length)\n",
        "bows_train"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BoW length: 367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5314x367 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 59416 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLd4g4oMy-cz"
      },
      "source": [
        "bows_valid = cv.transform(df_valid.text)\n",
        "bows_valid.sort_indices() # comes from TF2.0 sparse implementation, obscure requirement\n",
        "bows_test = cv.transform(df_test.text)\n",
        "bows_test.sort_indices() # comes from TF2.0 sparse implementation, obscure requirement\n",
        "bows_train=cv.transform(df_train.text)\n",
        "bows_train.sort_indices() # comes from TF2.0 sparse implementation, obscure requirement\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHBFdIlO8S13",
        "outputId": "c7d91dc1-7d2f-4b49-97ac-27514f5ec6b8"
      },
      "source": [
        "bows_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57_ybJKay-c5"
      },
      "source": [
        "# Feladat: A modell\n",
        "\n",
        "Felépítünk Kerasban egy egyszerű feed-forward neurális bináris osztályozó modellt, amelyet keresztentrópia veszteségfüggvénnyel tanítunk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrMQFWqI3I6x"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "data_rows_number=bows_train.shape[0]\n",
        "data_columns_number=bows_train.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "# KERAS FUNKCIONÁLIS API-T HASZNÁLUNK!\n",
        "\n",
        "\n",
        "# Paraméterek\n",
        "############\n",
        "\n",
        "hidden_size = 100\n",
        "\n",
        "# Model\n",
        "#######\n",
        "# Definiáljuk (példányosítsuk) az input réteget\n",
        "# Adjuk meg neki a shape paraméterben a BoW reprezentáció hosszát, mint vektort\n",
        "# vigyázzunk, mert a shape _EGY ELEMŰ TUPLE-T_ fogad el!!!\n",
        "inputs = Input(shape=(bow_length,))\n",
        "\n",
        "# Hidden layer\n",
        "##############\n",
        "# Definiáljuk a rejtett sűrű réteget, mely a fenti paraméterrel állítható méretű\n",
        "# Használjunk ReLU aktivációs funkciót (bővebben később)\n",
        "# Adjuk meg bemenetként az input-ot a rejtett rétegnek\n",
        "# Ügyeljünk rá, hogy a Keras funkcionális API-ban a layert meghatározó paraméterek \n",
        "# a példányosítás körébe tartoznak, a réteg inputja pedig már a példány hívásához!\n",
        "# (A zárójelekben van a mágia...)\n",
        "\n",
        "hidden_output = Dense(hidden_size, activation='relu')(inputs)\n",
        "\n",
        "# Softmax \n",
        "#########\n",
        "# Definiáljuk a kimeneti Softmax réteget\n",
        "# (Ami egy sűrű réteg Softmax aktivációval...)\n",
        "# Emlékezzünk, pontosan két osztályunk van\n",
        "# És a rejtett réteg kimenetével \"etetjük\"\n",
        "predictions = Dense(1000, activation='softmax')(hidden_output)\n",
        "\n",
        "# Teljes model\n",
        "##############\n",
        "# Nincs más hátra, mint hogy létrehozzuk a model példányt\n",
        "# Bemenetre és kimenetre figyeljünk!\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# Optimalizáló\n",
        "##############\n",
        "# Most fixen ezt használjuk.\n",
        "optimizer = SGD(lr=0.1)\n",
        " \n",
        "\n",
        "# Kompiláció tanítás \n",
        "####################\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy', # ezt a cross entropy variánst hasnzáljuk\n",
        "                                                      # mivel az input nem one-hot enkódolt\n",
        "              metrics=['accuracy']) #Training során az accuracy metirkát mérjük és printeljük."
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXSxYJfGCCDq"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzGouUrN3I6x"
      },
      "source": [
        "# Tréning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3phjSAJ3I6y",
        "outputId": "5bd8e9ab-1485-4a08-c1b9-6fa6d732d11f"
      },
      "source": [
        "model.fit(x=bows_train, \n",
        "          y=df_train.sentiment.values,\n",
        "          validation_data=(bows_valid, df_valid.sentiment.values),\n",
        "          epochs=30,\n",
        "          batch_size=200)\n",
        "\n",
        "# Kérlek, ne csak futtasd, értsd is meg!!!"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9814 - val_loss: 0.0563 - val_accuracy: 0.9842\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9831 - val_loss: 0.0550 - val_accuracy: 0.9842\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9842 - val_loss: 0.0565 - val_accuracy: 0.9842\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9849 - val_loss: 0.0482 - val_accuracy: 0.9842\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9866 - val_loss: 0.0449 - val_accuracy: 0.9842\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.0442 - val_accuracy: 0.9842\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0419 - accuracy: 0.9874 - val_loss: 0.0441 - val_accuracy: 0.9819\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.0428 - val_accuracy: 0.9842\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9870 - val_loss: 0.0410 - val_accuracy: 0.9842\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 0.0415 - val_accuracy: 0.9819\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.0402 - val_accuracy: 0.9842\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9893 - val_loss: 0.0380 - val_accuracy: 0.9842\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9885 - val_loss: 0.0375 - val_accuracy: 0.9842\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 0.0410 - val_accuracy: 0.9819\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.0364 - val_accuracy: 0.9842\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 0.0384 - val_accuracy: 0.9819\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0373 - val_accuracy: 0.9842\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 0.0348 - val_accuracy: 0.9865\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0345 - val_accuracy: 0.9865\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0352 - val_accuracy: 0.9865\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.0351 - val_accuracy: 0.9865\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.0338 - val_accuracy: 0.9865\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0324 - val_accuracy: 0.9865\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.0313 - val_accuracy: 0.9865\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0307 - val_accuracy: 0.9865\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 0.0327 - val_accuracy: 0.9865\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0302 - val_accuracy: 0.9865\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.0303 - val_accuracy: 0.9865\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0341 - val_accuracy: 0.9819\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.0308 - val_accuracy: 0.9865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1bcc76f5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIGukGXV3I6y"
      },
      "source": [
        "# Predikció"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI6GoLbl3I6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0fc108-0ecd-468d-dca9-308512c221ce"
      },
      "source": [
        "print(\"=== INTERACTIVE DEMO ===\")\n",
        "while True:\n",
        "    s = input(\"Enter a short text to evaluate or press return to quit: \")\n",
        "    if s == \"\":\n",
        "        break\n",
        "    else:\n",
        "        bow = cv.transform([s])\n",
        "        prob_pred = model.predict(bow[0])\n",
        "        print(f\"Positive vs negative sentiment probability: {prob_pred[0,1]} vs {prob_pred[0,0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== INTERACTIVE DEMO ===\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}